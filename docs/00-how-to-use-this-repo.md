# How to Use This Repository

## Overview

This repository is a **JIT optimization laboratory** designed to help advanced developers build an intuitive understanding of how Node.js and V8 optimize JavaScript code—and more importantly, how to detect and avoid deoptimizations that kill performance.

## Philosophy

**Evidence over cargo culting.** Every claim is backed by runnable experiments and measurable evidence. You'll learn to:
- Form hypotheses about optimization behavior
- Design minimal experiments to test them
- Gather concrete evidence (traces, profiles)
- Understand the "why" behind V8's decisions
- Apply mitigations intelligently, not mechanically

## Prerequisites

- **Node.js**: v18+ LTS recommended (tested on v20/v22)
- **Package manager**: npm or pnpm (examples use npm)
- **Time commitment**: 15-30 minutes per day for focused learning
- **Background**: Comfortable with JavaScript; some systems/performance intuition helpful

## Quick Start

```bash
# Install (minimal or zero dependencies)
npm install

# Run your first experiment
npm run exp -- --exp 01-hidden-classes --variant baseline
npm run exp -- --exp 01-hidden-classes --variant deopt

# With V8 tracing to see what happened
npm run exp -- --exp 01-hidden-classes --variant baseline --trace on
npm run exp -- --exp 01-hidden-classes --variant deopt --trace on

# Generate a summary report
npm run summarize
```

## Learning Path (Recommended Sequence)

### Phase 1: Foundations (Days 1-3)
1. Read `docs/01-v8-optimization-mental-model.md` - understand the big picture
2. Read `docs/02-tooling-node-v8-flags.md` - learn your instruments
3. Run `01-hidden-classes` experiment (all variants, with traces)
4. Run `02-inline-caches` experiment
5. Study the trace outputs; correlate with code

**Goal**: Can explain "hidden class" and "inline cache" with evidence.

### Phase 2: Core Deopt Triggers (Days 4-7)
6. Work through experiments `03-elements-kinds` through `06-try-catch-and-bailouts`
7. For each: predict behavior → run baseline → run deopt → examine traces → verify prediction
8. Read `docs/03-deopt-bestiary.md` as a reference while experimenting

**Goal**: Can predict common deopt triggers and verify with traces.

### Phase 3: Subtle Pitfalls (Days 8-12)
9. Experiments `07-arguments-and-rest` through `12-string-concats-and-slices`
10. Focus on "why does this seemingly innocent code deopt?"
11. Practice mitigation patterns from `docs/04-patterns-for-stable-performance.md`

**Goal**: Can spot subtle deopt triggers in code reviews.

### Phase 4: Real-World Integration (Days 13-15)
12. Study `13-json-parse-shapes`, `15-node-buffer-and-typedarrays`, `17-async-await-microtasks`
13. Read `docs/05-node-runtime-perf-gotchas.md`
14. Run `20-realistic-mini-server-hotpath` (full scenario)
15. Profile a small piece of your own codebase

**Goal**: Can apply optimization thinking to production code.

### Phase 5: Mastery (Ongoing)
16. Extend with custom experiments using `experiments/_template`
17. Test edge cases you encounter
18. Contribute findings back to team/community

## Daily Practice Loop (15-30 min)

A sustainable practice routine:

1. **Pick one experiment** (5 min)
   - Choose based on current curiosity or recent code you've written

2. **Hypothesize** (2 min)
   - Before running: what should optimize? What should deopt? Why?

3. **Run experiments** (5 min)
   - Baseline + deopt variant, with traces

4. **Examine evidence** (8 min)
   - Read trace output
   - Check timing differences
   - Note deopt reasons

5. **Reflect & document** (5 min)
   - Was your hypothesis correct?
   - What surprised you?
   - How would you apply this insight?

## Repository Structure

```
/
├── README.md                  # Start here (learning route, quick links)
├── docs/                      # Conceptual guides & references
│   ├── 00-how-to-use-this-repo.md
│   ├── 01-v8-optimization-mental-model.md
│   ├── 02-tooling-node-v8-flags.md
│   ├── 03-deopt-bestiary.md
│   ├── 04-patterns-for-stable-performance.md
│   ├── 05-node-runtime-perf-gotchas.md
│   └── 06-glossary.md
├── scripts/
│   ├── run-experiment.js     # Main experiment runner
│   └── summarize-results.js  # Parse artifacts into readable reports
├── experiments/              # 20 runnable experiments
│   ├── _template/           # Copy this to create new experiments
│   ├── 01-hidden-classes/
│   ├── 02-inline-caches/
│   └── ...
└── artifacts/               # Generated by experiments (gitignored)
```

## How to Run Experiments

### Basic Usage

```bash
npm run exp -- --exp <experiment-name> --variant <baseline|deopt|fixed>
```

### With Tracing (see what V8 is doing)

```bash
npm run exp -- --exp 01-hidden-classes --variant deopt --trace on
```

This runs Node with `--trace-opt --trace-deopt --trace-ic` flags and captures output.

### With Profiling

```bash
npm run exp -- --exp 05-polymorphism-megamorphism --variant deopt --profile on
```

Generates a `.cpuprofile` file you can load in Chrome DevTools.

### Control Warmup & Iterations

```bash
npm run exp -- --exp 03-elements-kinds --variant baseline --warmup 5000 --repeat 10000
```

### All Options

- `--exp <name>`: Experiment folder name (required)
- `--variant <baseline|deopt|fixed>`: Which variant to run (required)
- `--trace <on|off>`: Enable V8 trace flags (default: off)
- `--profile <on|off>`: Capture CPU profile (default: off)
- `--warmup <N>`: Warmup iterations (default: 1000)
- `--repeat <N>`: Measurement iterations (default: 100000)

## How to Read Results

### Timing Output

Each experiment prints timing information:
```
Variant: baseline
Warmup: 1000 iterations
Measurement: 100000 iterations
Time: 45.231ms
Avg per iteration: 452.31ns
```

### Trace Output (when --trace on)

Located in `artifacts/<exp>/<variant>/<timestamp>/trace.log`:

Look for:
- `[marking 0x... <functionName> for optimization]` - function got optimized
- `[deoptimizing (DEOPT soft): begin 0x... <functionName>]` - deopt happened
- Deopt reason (e.g., "Insufficient type feedback", "Wrong map")

### CPU Profiles (when --profile on)

Open `.cpuprofile` files in Chrome DevTools:
1. Open DevTools → Performance tab
2. Click "Load profile"
3. Select the `.cpuprofile` file

Look for time spent in optimized vs unoptimized code.

## Interpreting Results

### "Good" Performance Signals
- Functions marked for optimization
- No deopts during measurement phase
- Stable timing across runs

### "Bad" Performance Signals
- Repeated deopts (`DEOPT` in trace)
- Functions never optimized
- Timing variance >10% across runs

### Deopts That Matter vs. Don't Matter

Not all deopts are bad:
- **Harmless**: One-time deopts during warmup on cold paths
- **Harmful**: Repeated deopts on hot paths (inner loops, request handlers)

See `docs/03-deopt-bestiary.md` for details.

## Success Criteria

You've mastered this material when you can:

1. **Predict**: Look at code and predict likely deopt triggers
2. **Verify**: Use traces to confirm or refute predictions
3. **Explain**: Articulate _why_ a deopt happens (not just "it's bad")
4. **Mitigate**: Apply targeted fixes without cargo-culting
5. **Judge**: Decide when optimization matters vs. premature optimization

## Extending This Repository

To add your own experiments:

1. Copy `experiments/_template/` to `experiments/XX-your-topic/`
2. Fill in `README.md` with hypothesis & what to look for
3. Write `baseline.js` (optimizable), `deopt.js` (triggers deopt), `fixed.js` (mitigation)
4. Run with the experiment runner
5. Document findings

See `experiments/_template/README.md` for detailed guidance.

## Common Pitfalls

1. **Not warming up enough**: V8 needs time to observe types and optimize
2. **Measuring side effects**: Ensure loop bodies do real work (avoid dead code elimination)
3. **Over-generalizing**: V8 behavior can vary by version; state your Node version
4. **Ignoring real-world context**: Hot paths matter; cold paths don't
5. **Cargo cult optimization**: Understand _why_ before applying patterns

## Getting Help

- Check `docs/06-glossary.md` for terminology
- Review similar experiments for patterns
- Examine trace logs carefully - they tell the story
- Node version matters: `node --version` when reporting findings

## Next Steps

1. Read `docs/01-v8-optimization-mental-model.md`
2. Run your first experiment
3. Follow the learning path above
4. Practice daily

**Remember**: The goal is intuition + evidence, not memorization.
